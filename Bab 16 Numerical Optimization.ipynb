{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7107d2ea-2708-48d7-bb86-92cfae23560e",
   "metadata": {},
   "source": [
    "# Algoritma 16.1 (Preconditioned CG for Reduced System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d845113d-db6d-4693-9703-20d80f0b4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preconditioned_cg(Z, G, Wzz, c2, x0, tol=1e-6, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 16.1: Preconditioned CG for Reduced Systems.\n",
    "    \n",
    "    Parameters:\n",
    "    Z : ndarray\n",
    "        Matrix Z.\n",
    "    G : ndarray\n",
    "        Matrix G.\n",
    "    Wzz : ndarray\n",
    "        Preconditioner (assumed to be invertible).\n",
    "    c2 : ndarray\n",
    "        Vector c2.\n",
    "    x0 : ndarray\n",
    "        Initial point x.\n",
    "    tol : float, optional\n",
    "        Convergence tolerance.\n",
    "    max_iter : int, optional\n",
    "        Maximum number of iterations.\n",
    "    \n",
    "    Returns:\n",
    "    x : ndarray\n",
    "        Solution vector.\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    r_z = Z.T @ G @ Z @ x + c2  # Compute initial residual\n",
    "    g_z = np.linalg.solve(Wzz, r_z)  # Apply preconditioner\n",
    "    d_z = -g_z  # Initial direction\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        alpha = (r_z.T @ g_z) / (d_z.T @ Z.T @ G @ Z @ d_z)  # Step size\n",
    "        x = x + alpha * d_z  # Update x\n",
    "        r_z_new = r_z + alpha * (Z.T @ G @ Z @ d_z)  # Compute new residual\n",
    "        \n",
    "        if np.linalg.norm(r_z_new) < tol:\n",
    "            break  # Convergence check\n",
    "        \n",
    "        g_z_new = np.linalg.solve(Wzz, r_z_new)  # Apply preconditioner\n",
    "        beta = (r_z_new.T @ g_z_new) / (r_z.T @ g_z)  # Compute beta\n",
    "        d_z = -g_z_new + beta * d_z  # Update search direction\n",
    "        \n",
    "        r_z = r_z_new\n",
    "        g_z = g_z_new\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9bdfe-8b6a-4836-a256-86f7160b2e06",
   "metadata": {},
   "source": [
    "# Algoritma 16.2 (Projected CG Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fd31e9-a254-45a2-8ec6-7849f30d750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_cg(G, P, c, A, b, x0, tol=1e-6, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Projected Conjugate Gradient (CG) Method.\n",
    "    \n",
    "    Parameters:\n",
    "        G : numpy.ndarray\n",
    "            Symmetric positive definite matrix.\n",
    "        P : function\n",
    "            Projection operator that ensures feasibility.\n",
    "        c : numpy.ndarray\n",
    "            Constant vector.\n",
    "        A : numpy.ndarray\n",
    "            Matrix defining constraints Ax = b.\n",
    "        b : numpy.ndarray\n",
    "            Right-hand side of constraints.\n",
    "        x0 : numpy.ndarray\n",
    "            Initial feasible point satisfying Ax = b.\n",
    "        tol : float, optional\n",
    "            Convergence tolerance (default: 1e-6).\n",
    "        max_iter : int, optional\n",
    "            Maximum number of iterations (default: 1000).\n",
    "\n",
    "    Returns:\n",
    "        x : numpy.ndarray\n",
    "            Solution vector.\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    r = G @ x + c\n",
    "    g = P(r)\n",
    "    d = -g\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        Gd = G @ d\n",
    "        alpha = (r.T @ g) / (d.T @ Gd)\n",
    "        x = x + alpha * d\n",
    "        r_new = r + alpha * Gd\n",
    "        g_new = P(r_new)\n",
    "        beta = (r_new.T @ g_new) / (r.T @ g)\n",
    "        d = -g_new + beta * d\n",
    "        r = r_new\n",
    "        g = g_new\n",
    "\n",
    "        if np.linalg.norm(r) < tol:\n",
    "            break\n",
    "            \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb79256-8a8a-47b4-a7a4-c03dfeb771d7",
   "metadata": {},
   "source": [
    "# Algoritma 16.3 (Active-Set Method for Convex QP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a16165f-0c01-41c5-9371-0903f89c39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qp_active_set(Q, c, A, b, E, I, tol=1e-6, max_iter=100):\n",
    "    \"\"\"\n",
    "    Solves a convex quadratic programming (QP) problem using the Active-Set Method.\n",
    "    \n",
    "    Minimize: (1/2) x^T Q x + c^T x\n",
    "    Subject to: Ax = b, i in E, Ax >= b, i in I\n",
    "    \n",
    "    Parameters:\n",
    "        Q (numpy.ndarray): Positive semi-definite matrix of the quadratic term.\n",
    "        c (numpy.ndarray): Linear term vector.\n",
    "        A (numpy.ndarray): Constraint matrix.\n",
    "        b (numpy.ndarray): Constraint vector.\n",
    "        E (list): Index of equality constraint.\n",
    "        I (list): Index of inequality constraint.\n",
    "        tol (float): Tolerance for stopping criteria.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "    \n",
    "    Returns:\n",
    "        x (numpy.ndarray): Optimal solution.\n",
    "    \"\"\"\n",
    "    m, n = A.shape  # Number of constraints and variables\n",
    "    \n",
    "    # Define a feasible point x\n",
    "    \n",
    "    x = x0.copy()\n",
    "    W = W0.copy()\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Solve Q p_k = -c with active constraints\n",
    "        Z = np.eye(n)  # Assume identity for simplicity, should be computed properly\n",
    "        p = np.linalg.solve(Q, -c)  # Newton step direction\n",
    "        \n",
    "        if np.linalg.norm(p) < tol:\n",
    "            # Compute Lagrange multipliers\n",
    "            lambdas = np.linalg.lstsq(A[W, :], -c, rcond=None)[0]\n",
    "            \n",
    "            if np.all(lambdas >= 0):\n",
    "                return x  # Optimal solution found\n",
    "            \n",
    "            # Remove the most negative Lagrange multiplier\n",
    "            j = np.argmin(lambdas)\n",
    "            W.remove(W[j])\n",
    "        else:\n",
    "            # Compute step size\n",
    "            alpha = 1.0  # Should compute based on constraints\n",
    "            \n",
    "            x_new = x + alpha * p\n",
    "            \n",
    "            # Check for blocking constraints\n",
    "            blocking_constraints = [i for i in range(m) if A[i, :] @ x_new > b[i] + tol]\n",
    "            if blocking_constraints:\n",
    "                W.append(blocking_constraints[0])\n",
    "            \n",
    "            x = x_new\n",
    "    \n",
    "    return x  # Return last computed x if max_iter is reached\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ba4d8-68e8-4e38-a671-3a9b139255d6",
   "metadata": {},
   "source": [
    "# Algoritma 16.4 (Predictor-Corrector Algorithm for QP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add9dafd-5d34-4799-a905-7336b003972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_corrector_qp(x0, y0, lambd0, solve_kkt_system, max_iters=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Predictor-Corrector Algorithm for Quadratic Programming.\n",
    "    \n",
    "    Parameters:\n",
    "    x0, y0, lambd0: Initial primal and dual variables (assumed to be feasible and positive).\n",
    "    solve_kkt_system: Function that solves the KKT system given inputs.\n",
    "    max_iters: Maximum number of iterations.\n",
    "    tol: Convergence tolerance.\n",
    "    \"\"\"\n",
    "    x, y, lambd = x0, y0, lambd0\n",
    "    m = len(y)\n",
    "    \n",
    "    for k in range(max_iters):\n",
    "        # Solve for affine direction (σ = 0)\n",
    "        dx_aff, dy_aff, dlambda_aff = solve_kkt_system(x, y, lambd, sigma=0)\n",
    "        \n",
    "        # Compute step size for affine direction\n",
    "        alpha_aff = max_alpha(y, lambd, dy_aff, dlambda_aff)\n",
    "        \n",
    "        # Compute μ and μ_aff\n",
    "        mu = np.dot(y, lambd) / m\n",
    "        mu_aff = (np.dot(y + alpha_aff * dy_aff, lambd + alpha_aff * dlambda_aff)) / m\n",
    "        \n",
    "        # Compute centering parameter σ\n",
    "        sigma = (mu_aff / mu) ** 3\n",
    "        \n",
    "        # Solve for corrector direction\n",
    "        dx, dy, dlambda = solve_kkt_system(x, y, lambd, sigma)\n",
    "        \n",
    "        # Choose step size τ\n",
    "        tau_x = choose_tau(y, lambd, dy, dlambda)\n",
    "        \n",
    "        # Update variables\n",
    "        x += tau_x * dx\n",
    "        y += tau_x * dy\n",
    "        lambd += tau_x * dlambda\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(dx) < tol and np.linalg.norm(dy) < tol and np.linalg.norm(dlambda) < tol:\n",
    "            break\n",
    "    \n",
    "    return x, y, lambd\n",
    "\n",
    "def max_alpha(y, lambd, dy, dlambda):\n",
    "    \"\"\"Compute maximum step size α_aff\"\"\"\n",
    "    alpha_y = np.min([-y[i] / dy[i] for i in range(len(y)) if dy[i] < 0] + [1])\n",
    "    alpha_lambda = np.min([-lambd[i] / dlambda[i] for i in range(len(lambd)) if dlambda[i] < 0] + [1])\n",
    "    return min(alpha_y, alpha_lambda, 1)\n",
    "\n",
    "def choose_tau(y, lambd, dy, dlambda):\n",
    "    \"\"\"Choose step size τ according to α_pri and α_dual\"\"\"\n",
    "    alpha_pri = max_alpha(y, lambd, dy, dlambda)\n",
    "    alpha_dual = max_alpha(y, lambd, dy, dlambda)\n",
    "    return min(alpha_pri, alpha_dual)\n",
    "\n",
    "# Note: The function `solve_kkt_system(x, y, lambd, sigma)` needs to be defined separately based on the problem structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5269e-542f-4086-a8ab-e2f456c7ec3c",
   "metadata": {},
   "source": [
    "# Algoritma 16.5 (Gradient Projection Method for QP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f694f5cb-5228-485e-a20a-b4ad2fa9f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Solution: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def gradient_projection_qp(Q, c, A, b, x0, tol=1e-6, max_iter=100):\n",
    "    \"\"\"\n",
    "    Gradient Projection Method for Quadratic Programming (QP)\n",
    "    Minimize: 0.5 * x^T Q x + c^T x\n",
    "    Subject to: Ax <= b\n",
    "    \n",
    "    Parameters:\n",
    "    Q : numpy.ndarray\n",
    "        Quadratic term matrix (must be positive semi-definite)\n",
    "    c : numpy.ndarray\n",
    "        Linear term vector\n",
    "    A : numpy.ndarray\n",
    "        Constraint matrix\n",
    "    b : numpy.ndarray\n",
    "        Constraint vector\n",
    "    x0 : numpy.ndarray\n",
    "        Initial feasible point\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    x : numpy.ndarray\n",
    "        Optimal solution\n",
    "    \"\"\"\n",
    "    def kkt_conditions_satisfied(x, grad):\n",
    "        return np.linalg.norm(grad) < tol\n",
    "    \n",
    "    def projection_onto_feasible_set(x):\n",
    "        from scipy.optimize import linprog\n",
    "        res = linprog(c=np.zeros_like(x), A_ub=A, b_ub=b, bounds=[(None, None)]*len(x), method='highs')\n",
    "        return res.x if res.success else x\n",
    "    \n",
    "    x = x0.copy()\n",
    "    for k in range(max_iter):\n",
    "        grad = Q @ x + c\n",
    "        if kkt_conditions_satisfied(x, grad):\n",
    "            return x  # Stop if KKT conditions are met\n",
    "        \n",
    "        # Compute the Cauchy point\n",
    "        pk = -grad\n",
    "        alpha = 1.0  # Simple step size (can be improved with line search)\n",
    "        xc = x + alpha * pk\n",
    "        \n",
    "        # Projection step to find a feasible approximate solution\n",
    "        x_plus = projection_onto_feasible_set(xc)\n",
    "        \n",
    "        # Ensure descent\n",
    "        if 0.5 * x_plus.T @ Q @ x_plus + c.T @ x_plus <= 0.5 * xc.T @ Q @ xc + c.T @ xc:\n",
    "            x = x_plus\n",
    "        else:\n",
    "            break  # If no improvement, stop\n",
    "    \n",
    "    return x  # Return last feasible solution\n",
    "\n",
    "# Example Usage\n",
    "Q = np.array([[2, 0], [0, 2]])  # Example positive semi-definite matrix\n",
    "c = np.array([-2, -5])  # Linear term\n",
    "A = np.array([[1, 1], [-1, 2], [2, 1]])  # Constraint matrix\n",
    "b = np.array([2, 2, 3])  # Constraint vector\n",
    "x0 = np.array([0, 0])  # Initial feasible point\n",
    "\n",
    "optimal_x = gradient_projection_qp(Q, c, A, b, x0)\n",
    "print(\"Optimal Solution:\", optimal_x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
